{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Notebook para automatizar fiscalização - Específico para Empresas do Simples Nacional\n",
    "---\n",
    "\n",
    "Esse notebook tem por propósito automatizar a fiscalização por monitoramento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração Inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Configurações Iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1. Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from datetime import datetime as dt \n",
    "from dateutil.relativedelta import relativedelta\n",
    "from connection import DadosEscriturais, DadosOperacoes, DadosCadastrais, DadosParametrizados, DadosDebitos\n",
    "from external_connection import DadosCadastraisRFB, DadosCadastraisJUCERR\n",
    "from EFD.EFDLocal import EFDLocal\n",
    "import os \n",
    "import warnings\n",
    "from report_generator import RelatorioAuditoria\n",
    "\n",
    "\n",
    "relatorio = {}\n",
    "anexos = {}\n",
    "indice_anexo = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2. Configurações básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inicio=dt(2022, 1, 1)\n",
    "data_fim=dt(2022, 1, 31)\n",
    "cnpj = '29563548000121'\n",
    "cgf = '24.033751-5'\n",
    "\n",
    "valor_minimo_significancia = 10000\n",
    "\n",
    "endereco_pasta_audit = r'C:\\Users\\Jimmy_Usuário\\Documents\\Auditor_Fiscal\\Planos de Trabalho - DIFIS\\022024\\Fiscalizações\\Life Nutri\\Dados'\n",
    "\n",
    "doc = RelatorioAuditoria(cnpj='00000000000100', \n",
    "                         cgf='24-000.212', \n",
    "                         ordem_servico = '20123120309', \n",
    "                         proc_sei = '912839128301293812093', \n",
    "                         data_inicio = dt(2022, 1, 1), \n",
    "                         data_fim = dt(2023, 12, 31), \n",
    "                         nome_arquivo = f'relatorio_preliminar_auditoria_{cnpj}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.2.1. Tratamentos adicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_months = (data_fim.year - data_inicio.year) * 12 + data_fim.month - data_inicio.month + 1   # Calcular quantidade de meses de fiscalização\n",
    "meses_audit = [(data_inicio + relativedelta(months=x)).strftime('%m/%Y') for x in range(num_months)] # Transformar quantidade de meses de fiscalização em formato MM/YYYY\n",
    "\n",
    "warnings.filterwarnings('ignore')   # Ignorar alguns avisos de deprecação de funções do pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Coleta de PGDAS e GIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coleta de GIM\n",
    "gim = DadosEscriturais.GIM(cgf=cgf, data_inicio=data_inicio, data_fim=data_fim)\n",
    "obrigatoriedade = DadosEscriturais.BuscarObrigatoriedade(cgf=cgf, data_inicio=data_inicio, data_fim=data_fim)\n",
    "\n",
    "# Salvar GIM importada (para documentação de auditoria)\n",
    "# gim.save(path=endereco_pasta_audit+r'\\escrituracao_GIM.xlsx')\n",
    "\n",
    "\n",
    "# Coleta de PGDAS \n",
    "pgdas = DadosEscriturais.PGDAS(cnpj=cnpj, data_inicio=data_inicio, data_fim=data_fim)\n",
    "# pgdas.save(path=endereco_pasta_audit+r'\\escrituracao_PGDAS.xlsx', sheet_name='PGDAS')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Coleta de documentos adicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrizacoes = DadosParametrizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Coleta da Inscrição no CNPJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_cnpj = DadosCadastraisRFB(cnpj=cnpj)\n",
    "dados_jucerr = DadosCadastraisJUCERR(cnpj=cnpj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Coleta da inscrição no CGF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuperado 1 registros!\n",
      "Recuperado 3 registros!\n"
     ]
    }
   ],
   "source": [
    "cadastro = DadosCadastrais.CadastroAtualEstadual(cnpj)\n",
    "cadastro_historico = DadosCadastrais.HistoricoCadastroEstadual(cnpj)\n",
    "\n",
    "cadastro.save(path=endereco_pasta_audit+r'\\cadastro_atual_estadual.xlsx')\n",
    "cadastro_historico.save(path=endereco_pasta_audit+r'\\historico_cadastro_estadual.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Coleta de Dsot e Pagamentos Antecipados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuperado 0 registros!\n"
     ]
    }
   ],
   "source": [
    "dsot = DadosDebitos.DSOT(cgf, data_inicio, data_fim)\n",
    "pag_antecipado = DadosDebitos.DebitosAntecipacaoParcialPagos(cgf, data_inicio, data_fim)\n",
    "\n",
    "dsot.save(path=endereco_pasta_audit+r'\\dsot_periodo.xlsx', sheet_name='DSOT')\n",
    "# pag_antecipado.save(path=endereco_pasta_audit+r'\\pag_antecipado_periodo.xlsx', sheet_name='PagamentoAntecipado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Coleta de Documentos Fiscais Não Escriturais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFeEntrada = DadosOperacoes.NotasFiscaisEntrada(cnpj=cnpj, data_inicio=data_inicio, data_fim=data_fim)\n",
    "NFeSaida = DadosOperacoes.NotasFiscaisSaida(cnpj=cnpj, data_inicio=data_inicio, data_fim=data_fim)\n",
    "NFCe = DadosOperacoes.NotasFiscaisConsumidor(cnpj=cnpj, data_inicio=data_inicio, data_fim=data_fim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.1. Salvando arquivos para consulta posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar Documentação de Auditoria\n",
    "# NFeEntrada.save(path=endereco_pasta_audit+r'\\notas_fiscais_entrada.xlsx', sheet_name='NFe_Entrada')\n",
    "# NFeSaida.save(path=endereco_pasta_audit+r'\\notas_fiscais_saida.xlsx', sheet_name='NFe_Saida')\n",
    "# NFCe.save(path=endereco_pasta_audit+r'\\notas_fiscais_ao_consumidor.xlsx', sheet_name='NFCE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Auditoria de Obrigações Acessórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_metodo = 'Auditoria de Obrigações Acessórias e Cadastrais'\n",
    "texto = f\"No dia {dt.today().strftime('%d/%m/%Y')}, foi realizada auditoria de cumprimento das obrigações acessórias e cadastrais em geral, por meio das seguintes verificações: \\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Verificação da inscrição no CNPJ\n",
    "\n",
    "- Verificar se está inscrito;\n",
    "- Verificar o período de inscrição;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dados_cnpj.BuscarCadastro()\n",
    "\n",
    "relatos = {}\n",
    "\n",
    "\n",
    "if temp['SituacaoCadastral'].values in ('Ativa', 'Ativo'):\n",
    "    msg = f'Contribuinte está inscrito no CNPJ desde {pd.to_datetime(temp[\"DataCadastro\"].values[0]).strftime(\"%d/%m/%Y\")}.'\n",
    "    del temp\n",
    "\n",
    "else:\n",
    "    msg = f'Contribuinte está com inscrição desativada conforme Anexo {indice_anexo}.'\n",
    "    anexos[f'Anexo {indice_anexo} - Cadastro Desativado'] = [temp]\n",
    "    indice_anexo += 1\n",
    "\n",
    "\n",
    "criterio = 'Contribuinte inscrito no Cadastro Nacional de Pessoas Jurídicas (CNPJ)'\n",
    "explicacao_adicional = f'Foi acessado o banco de dados CNPJ da Receita Federal no dia {dt.today().strftime(\"%d/%m/%Y\")} com a finalidade de confirmar a situação da auditada, especificamente se a mesma está com inscrição ativa no órgão federal. '\n",
    "\n",
    "doc.inserir_procedimento(nome_metodo=nome_metodo, texto=texto, resultado=msg, texto_adicional=explicacao_adicional, criterio = criterio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Verificação da inscrição no CGF \n",
    "\n",
    "- Verificar status da inscrição estadual no período de abrangência\n",
    "- Verificar regime de apuração\n",
    "- Verificar se o sócio-administrador está batendo com banco estadual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuperado 3 registros!\n"
     ]
    }
   ],
   "source": [
    "temp = cadastro_historico.retrieve()\n",
    "\n",
    "relatos = {}\n",
    "\n",
    "if temp['SituacaoCadastral'].values[-1] in ('A', 'N'):\n",
    "    msg = 'Contribuinte está ativo no CGF.'\n",
    "\n",
    "else:\n",
    "    msg = f'Contribuinte está com inscrição pendente, conforme Anexo II. Situação Cadastral atual: {temp[\"SituacaoCadastral\"].values[-1]}.'\n",
    "    anexos[f'Anexo {indice_anexo} - Histórico de Cadastro Geral da Fazenda'] = [temp]\n",
    "    indice_anexo += 1\n",
    "\n",
    "criterio = 'Contribuinte inscrito no Cadastro Geral da Fazenda (CGF)'\n",
    "explicacao_adicional = f'Foi acessado o banco de dados cadastrais da Receita Estadual (SEFAZ-RR) no dia {dt.today().strftime(\"%d/%m/%Y\")} com a finalidade de confirmar a situação cadastral da auditada, especificamente se a mesma está com inscrição ativa no órgão estadual. '\n",
    "\n",
    "doc.inserir_procedimento(nome_metodo=nome_metodo, texto=texto, resultado=msg, texto_adicional=explicacao_adicional, criterio = criterio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise NotImplementedError('Ainda não está pronto! Falta importar Socios do CGF!')\n",
    "socios_jucerr = dados_jucerr.BuscarSocios()\n",
    "# socios_cgf = DadosCadastrais.BuscarSocios(cnpj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Verificação de Emissão de Documentos Fiscais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O contribuinte está recebendo notas fiscais (de entrada) no período de abrangência.\n",
      "O contribuinte está emitindo Nota Fiscal Eletrônica de saída / Nota Fiscal ao Consumiddor Eletrônica!\n"
     ]
    }
   ],
   "source": [
    "relatos['Verificação de Emissão de Documentos Fiscais'] = []\n",
    "\n",
    "if NFeEntrada.quantidade()['QUANTIDADE'].values == 0:\n",
    "    msg = 'O contribuinte NÃO está recebendo notas fiscais (de entrada) no período de abrangência.'\n",
    "else:\n",
    "    msg = 'O contribuinte está recebendo notas fiscais (de entrada) no período de abrangência.'\n",
    "    \n",
    "print(msg)\n",
    "\n",
    "if NFeSaida.quantidade()['QUANTIDADE'].values == 0 and NFCe.quantidade()['QUANTIDADE'].values == 0:\n",
    "    msg = 'O contribuinte NÃO está emitindo nota fiscal de saída (inclusive NFCe)!'\n",
    "\n",
    "else:\n",
    "    msg = 'O contribuinte está emitindo Nota Fiscal Eletrônica de saída / Nota Fiscal ao Consumiddor Eletrônica!'\n",
    "    \n",
    "criterio = 'Contribuinte com emissão de documentos fiscais no período'\n",
    "print(msg)\n",
    "\n",
    "explicacao_adicional = f'Foi acessado o banco de dados da Receita Estadual (SEFAZ-RR) no dia {dt.today().strftime(\"%d/%m/%Y\")} com a finalidade de confirmar se a auditada está realizando emissões de documentos fiscais (de saída) e se está recebendo notas fiscais (de entrada). \\nEsta validação, contudo, se restringe às operações com mercadorias, não adentrando no espectro de emissão de documentos fiscais relativos à energia elétrica, serviços de transporte e serviços de comunicação.'\n",
    "\n",
    "doc.inserir_procedimento(nome_metodo=nome_metodo, texto=texto, resultado=msg, texto_adicional=explicacao_adicional, criterio = criterio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Verificação da declaração da Guia de Informação Mensal do ICMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuperado 0 registros!\n"
     ]
    }
   ],
   "source": [
    "# raise NotImplementedError('Excluir meses em que contribuinte estava pelo Simples Nacional')\n",
    "data_atual = data_inicio\n",
    "lista_periodos_sem_gim = []\n",
    "obrigatoriedade_gim = [data.strftime('%m/%Y') for data in obrigatoriedade[obrigatoriedade['OB_TIPO']=='GIM']['OB_DATA']]\n",
    "\n",
    "\n",
    "gim_importada = gim.retrieve()\n",
    "while data_atual <= data_fim:\n",
    "    if data_atual.strftime('%m/%Y') not in gim_importada[\"PERÍODO\"].values and data_atual.strftime('%m/%Y') in obrigatoriedade_gim:\n",
    "        lista_periodos_sem_gim.append(data_atual.strftime('%m/%Y'))\n",
    "    data_atual += relativedelta(months=1)\n",
    "\n",
    "if len(lista_periodos_sem_gim) != 0:\n",
    "    msg = 'Há meses com omissão de declaração de Guia de Informações Mensais no período de abrangência.'\n",
    "    \n",
    "elif len(obrigatoriedade_gim) == 0:\n",
    "    msg = 'O contribuinte não esteve obrigado a emitir qualquer Guia de Informações Mensais no período de abrangência.'\n",
    "    \n",
    "else:\n",
    "    msg = f'O contribuinte transmitiu todas as {len(obrigatoriedade_gim)} Guia de Informações Mensais obrigatórias no período de abrangência.'\n",
    "    del gim_importada\n",
    "\n",
    "criterio = 'Contribuinte com entrega de Guia de Informação Mensal do ICMS (GIM)'\n",
    "\n",
    "explicacao_adicional = f'Foi acessado o banco de dados da Receita Estadual (SEFAZ-RR) no dia {dt.today().strftime(\"%d/%m/%Y\")} com a finalidade de identificar se a auditada está declarando Guias de Informações Mensais de ICMS nos períodos em que consta como obrigatórios. \\nNão são validados, contudo, os valores declarados, mas tão somente a emissão de per si.'\n",
    "\n",
    "doc.inserir_procedimento(nome_metodo=nome_metodo, texto=texto, resultado=msg, texto_adicional=explicacao_adicional, criterio = criterio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Verificação da Declaração de PGDAS no período "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise NotImplementedError "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Auditoria dos Dados Cadastrais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Auditoria da Situação Fiscal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Verificação da existência de débitos constantes do DSOT\n",
    "\n",
    "\n",
    "---\n",
    "<center> Fundamentos Legais </center>\n",
    "\n",
    "---\n",
    " \n",
    "\n",
    "Art. 81. A exclusão do Simples Nacional, mediante comunicação da ME ou da EPP à RFB, em aplicativo disponibilizado no Portal do Simples Nacional, dar-se-á:\n",
    "\n",
    "[...]\n",
    "\n",
    "II - obrigatoriamente, quando:\n",
    "\n",
    "[...]\n",
    "\n",
    "d) possuir débito com o Instituto Nacional do Seguro Social (INSS), ou com as Fazendas Públicas Federal, Estadual ou Municipal, cuja exigibilidade não esteja suspensa, hipótese em que a exclusão: (Lei Complementar nº 123, de 2006, art. 17, inciso V; art. 30, inciso II)\n",
    "1. deverá ser comunicada até o último dia útil do mês subsequente ao da situação de vedação; e (Lei Complementar nº 123, de 2006, art. 30, § 1º, inciso II)\n",
    "2. produzirá efeitos a partir do ano-calendário subsequente ao da comunicação; ou(Lei Complementar nº 123, de 2006, art. 31, inciso IV)\n",
    "\n",
    "\n",
    "[...]\n",
    "\n",
    "---\n",
    "\n",
    "Art. 84. A exclusão de ofício da ME ou da EPP do Simples Nacional produzirá efeitos:\n",
    "\n",
    "[...]\n",
    "\n",
    "V - a partir do primeiro dia do mês seguinte ao da ocorrência, na hipótese de ausência ou irregularidade no cadastro fiscal federal, municipal ou, quando exigível, estadual; e (Lei Complementar nº 123, de 2006, art. 17, inciso XVI; art. 31, inciso II)\n",
    "\n",
    "[...]\n",
    "\n",
    "VI - a partir do ano-calendário subsequente ao da ciência do termo de exclusão, se a empresa estiver em débito com o Instituto Nacional do Seguro Social (INSS), ou com as Fazendas Públicas Federal, Estadual ou Municipal, cuja exigibilidade não esteja suspensa. (Lei Complementar nº 123, de 2006, art. 17, inciso V; art. 31, inciso IV)\n",
    "\n",
    "[...]\n",
    "\n",
    "§ 1º Na hipótese prevista nos incisos V e VI do caput, a comprovação da regularização do débito ou do cadastro fiscal, no prazo de até 30 (trinta) dias, contado da ciência da exclusão de ofício, possibilitará a permanência da ME ou da EPP como optante pelo Simples Nacional. (Lei Complementar nº 123, de 2006, art. 31, § 2º)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não há débitos registrados nos sistemas da SEFAZ-RR.\n"
     ]
    }
   ],
   "source": [
    "dsot_existente = dsot.retrieve()\n",
    "dsot_ativo = dsot_existente[dsot_existente['Suspensao']=='N']\n",
    "relatos = {}\n",
    "explicacoes_adicionais = []\n",
    "\n",
    "if dsot_existente.empty:\n",
    "    msg = 'Não há débitos registrados nos sistemas da SEFAZ-RR.'\n",
    "    del dsot_ativo\n",
    "    del dsot_existente\n",
    "\n",
    "elif dsot_ativo.empty: \n",
    "    msg = f'Há apenas débitos suspensos registrados nos sistemas da SEFAZ-RR, conforme Anexo {indice_anexo}'\n",
    "    anexos[f'Anexo {indice_anexo} - Tabelas de Débitos Fiscais em Aberto'] = [dsot_existente]\n",
    "    indice_anexo += 1\n",
    "    del dsot_ativo\n",
    "\n",
    "else: \n",
    "    valor_total_debito = sum(dsot_ativo['ValorPrincipal'] + dsot_ativo['ValorMulta'] + dsot_ativo['ValorJuros'] + dsot_ativo['ValorCorrecao'])\n",
    "    \n",
    "    msg = f'Há débitos registrados nos sistemas da SEFAZ-RR no montante de {valor_total_debito}, conforme Anexo {indice_anexo}'\n",
    "    anexos[f'Anexo {indice_anexo} - Tabelas de Débitos Fiscais em Aberto'] = [dsot_ativo] \n",
    "    indice_anexo += 1\n",
    "    del dsot_existente\n",
    "\n",
    "\n",
    "print(msg)\n",
    "criterio = 'Inexistências de créditos tributários lançados e não suspensos'\n",
    "\n",
    "explicacao_adicional = f'Foi acessado o banco de dados da Receita Estadual (SEFAZ-RR) no dia {dt.today().strftime(\"%d/%m/%Y\")} com a finalidade de identificar se a auditada possui pendências fiscais (débitos em aberto) nos períodos em auditoria. \\nNão são validados, contudo, os valores em débitos, mas tão somente a existência dos mesmos.'\n",
    "\n",
    "doc.inserir_procedimento(nome_metodo=nome_metodo, texto=texto, resultado=msg, texto_adicional=explicacao_adicional, criterio = criterio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Auditoria das Operações e Prestações de Entrada\n",
    "\n",
    "Objetivos:\n",
    "- Certificar desembaraço de notas fiscais \n",
    "- Certificar aquisições em relação ao faturamento\n",
    "\n",
    "\n",
    "---\n",
    "<center> Fundamentos Legais </center>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Art. 84. A exclusão de ofício da ME ou da EPP do Simples Nacional produzirá efeitos:\n",
    "\n",
    "[...]\n",
    "\n",
    "IV - a partir do próprio mês em que incorridas, hipótese em que a empresa ficará impedida de fazer nova opção pelo Simples Nacional nos 3 (três) anos-calendário subsequentes, nas seguintes hipóteses: (Lei Complementar nº 123, de 2006, art. 29, incisos II a XII e § 1º)\n",
    "\n",
    "[...]\n",
    "\n",
    "h) se for constatado que durante o ano-calendário o valor das despesas pagas supera em 20% (vinte por cento) o valor de ingressos de recursos no mesmo período, excluído o ano de início de atividade;\n",
    "\n",
    "i) se for constatado que durante o ano-calendário o valor das aquisições de mercadorias para comercialização ou industrialização, ressalvadas hipóteses justificadas de aumento de estoque, foi superior a 80% (oitenta por cento) dos ingressos de recursos no mesmo período, excluído o ano de início de atividade;\n",
    "\n",
    "[...]\n",
    "\n",
    "§ 6º Considera-se prática reiterada, para fins do disposto nas alíneas “d”, “j” e “k” do inciso IV do caput: (Lei Complementar nº 123, de 2006, art. 29, § 9º)\n",
    "\n",
    "I - a ocorrência, em 2 (dois) ou mais períodos de apuração, consecutivos ou alternados, de idênticas infrações, inclusive de natureza acessória, verificada em relação aos últimos 5 (cinco) anos-calendário, formalizadas por intermédio de auto de infração ou notificação de lançamento, em um ou mais procedimentos fiscais; ou\n",
    "\n",
    "II - a segunda ocorrência de idênticas infrações, caso seja constatada a utilização de artifício, ardil ou qualquer outro meio fraudulento que induza ou mantenha a fiscalização em erro, com o fim de suprimir ou reduzir o pagamento de tributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuperado 373 registros!\n",
      "Recuperado 17 registros!\n",
      "Recuperado 161 registros!\n"
     ]
    }
   ],
   "source": [
    "# Trazer dados para memória RAM \n",
    "nfe_entrada = NFeEntrada.retrieve()\n",
    "eventos_desemb = DadosOperacoes.EventosDesembaraco(tuple(nfe_entrada[nfe_entrada['DESTINO']=='INTERESTADUAL']['CHAVE_ACESSO'].values)).retrieve()\n",
    "eventos = DadosOperacoes.EventosNotas(tuple(nfe_entrada['CHAVE_ACESSO'].values)).retrieve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar as variáveis de relatório\n",
    "relatos = {}\n",
    "explicacoes_adicionais = []\n",
    "nome_metodo = 'Auditoria de Operações e Prestações de Entrada'\n",
    "texto = f\"No dia {dt.today().strftime('%d/%m/%Y')}, foi realizada auditoria de Operações e Prestações de Entrada, por meio das seguintes verificações: \\n \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Verificação de notas fiscais não desembaraçadas \n",
    "\n",
    "Cria-se uma tabela com as notas fiscais não desembaraçadas\n",
    "\n",
    "Regras:\n",
    "- Data de Desembaraço: Data de emissão + 90\n",
    "- Remove notas com passagem no posto e com código de evento de cancelamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foram encontradas 55 Notas Fiscais válidas e não desembaraçadas no período, conforme anexo 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Primeira parte - Obtendo documentos interestaduais\n",
    "nfe_n_desemb = nfe_entrada[(nfe_entrada['DESTINO']=='INTERESTADUAL')&(nfe_entrada['FINALIDADE'].isin(['NORMAL', 'DEVOLUÇÃO', 'N/A']))]\n",
    "\n",
    "# Segunda parte - Obtendo eventos de desembaraço para filtrar por não desembaraço\n",
    "nfe_n_desemb = nfe_n_desemb[~nfe_n_desemb['CHAVE_ACESSO'].isin(eventos_desemb['CHAVE_ACESSO'])]\n",
    "\n",
    "\n",
    "# Terceira Parte Encontrando data de desembaraço devida\n",
    "nfe_n_desemb['DataDesembaraçoPrevista'] = [linha + relativedelta(days=90) for linha in nfe_n_desemb['DT_EMISSAO']]\n",
    "\n",
    "\n",
    "# Quarta Parte - Filtrando pelos documentos com eventos\n",
    "eventos_canc = eventos[eventos['CODIGO_EVENTO'].isin(['210220', '210240'])]\n",
    "nfe_n_desemb = nfe_n_desemb[~(nfe_n_desemb['CHAVE_ACESSO'].isin(eventos_canc['CHAVE_ACESSO']))]\n",
    "\n",
    "# Sexta parte - Indicar existência de notas não desembaraçadas\n",
    "if not nfe_n_desemb.empty: \n",
    "    msg = f'Foram encontradas {len(nfe_n_desemb)} Notas Fiscais válidas e não desembaraçadas no período, conforme anexo {indice_anexo}'\n",
    "    anexos[f'Anexo {indice_anexo} - Notas Fiscais Interestaduais Não Desembaraçadas'] = [nfe_n_desemb]\n",
    "    indice_anexo += 1 \n",
    "\n",
    "else:\n",
    "    msg = f'Não foram encontradas Notas Fiscais não desembaraçadas no período.'\n",
    "    \n",
    "    del nfe_n_desemb\n",
    "\n",
    "print(msg)\n",
    "# Sexta parte - Salvar conjunto de notas não desembaraçadas\n",
    "del eventos_canc\n",
    "del eventos_desemb\n",
    "\n",
    "explicacao_adicional = f'Foi acessado o banco de dados da Receita Estadual (SEFAZ-RR) no dia {dt.today().strftime(\"%d/%m/%Y\")} com a finalidade de identificar se a auditada possui Notas Fiscais Eletrônicas interestaduais não desembaraçadas. Nesse contexto, são considerados os eventos de Desconhecimento da Operação, Não Realização da Operação e Cancelamentos. \\nNão são validados, contudo, os valores lançados no documento fiscal.'\n",
    "\n",
    "criterio = 'Notas Fiscais Interestaduais apresentadas à Secretaria da Fazenda de Roraima'\n",
    "# Documentar procedimento\n",
    "doc.inserir_procedimento(nome_metodo=nome_metodo, texto=texto, resultado=msg, texto_adicional=explicacao_adicional, criterio = 'Verificação de Notas Fiscais Não Desembaraçadas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Auditoria de Operações e Prestações de Saída\n",
    "\n",
    "Objetivo: \n",
    "- Certificar ausência de desempenho negativo (por mês)\n",
    "- Certificar ausência de desempenho negativo (por produto)\n",
    "- Certificar emissão de documentos fiscais \n",
    "\n",
    "---\n",
    "<center> Fundamentos Legais </center>\n",
    "\n",
    "---\n",
    "> RICMS-RR\n",
    "\n",
    "<b>Art. 858.</b> Para apuração das operações ou prestações realizadas pelo sujeito passivo, o fisco\n",
    "poderá utilizar quaisquer procedimentos tecnicamente idôneo, tais como:\n",
    "\n",
    "I – análise da escrita comercial e fiscal e de documentos fiscais e subsidiários;\n",
    "\n",
    "[...]\n",
    "\n",
    "<b>Art. 859.</b> Presumir-se-á operação ou prestação tributável não registrada, quando se constatar:\n",
    "\n",
    "[...]\n",
    "\n",
    "II – diferença apurada pelo cotejo entre as saídas registradas e o valor das saídas a preço de\n",
    "custo acrescido do lucro apurado mediante a aplicação de percentual fixado em portaria do Secretário de\n",
    "Estado da Fazenda; * Fixado pela SEFAZ/PORTARIA/GAB nº 137/2015, em 30% (trinta por cento)\n",
    "\n",
    "[...]\n",
    "\n",
    "\n",
    "VI – diferença apurada mediante controle quantitativo de mercadorias, assim entendido o\n",
    "confronto entre a quantidade de unidades estocadas e as quantidades de entradas e de saídas;\n",
    "\n",
    "[...]\n",
    "\n",
    "<b>Art. 860.</b> Constatada, por indicação na escrituração do contribuinte ou outro qualquer elemento\n",
    "de prova, a saída de mercadoria ou a prestação de serviço sem emissão de documento fiscal, a autoridade\n",
    "fiscal deve arbitrar o valor da operação ou da prestação.\n",
    "\n",
    "Parágrafo único. Para efeito de arbitramento da base de cálculo do imposto e de multa, sem\n",
    "prejuízo do disposto no artigo 37, será tomada como critério a média ponderada dos preços unitários das\n",
    "saídas ou entradas verificadas no período.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> Resolução CGSN 140/2018\n",
    "\n",
    "<b>Art. 84.</b> A exclusão de ofício da ME ou da EPP do Simples Nacional produzirá efeitos:\n",
    "\n",
    "[...]\n",
    "\n",
    "IV - a partir do próprio mês em que incorridas, hipótese em que a empresa ficará impedida de fazer nova opção pelo Simples Nacional nos 3 (três) anos-calendário subsequentes, nas seguintes hipóteses: (Lei Complementar nº 123, de 2006, art. 29, incisos II a XII e § 1º)\n",
    "\n",
    "\n",
    "[...]\n",
    "\n",
    "j) se for constatado que a empresa, de forma reiterada, não emite documento fiscal de venda ou prestação de serviço, observado o disposto nos arts. 59 a 61 e ressalvadas as prerrogativas do MEI nos termos da alínea \"a\" do inciso II do art. 106; e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuperado 373 registros!\n",
      "Recuperado 209 registros!\n",
      "Recuperado 1010 registros!\n",
      "Recuperado 161 registros!\n",
      "Recuperado 19 registros!\n",
      "Recuperado 0 registros!\n"
     ]
    }
   ],
   "source": [
    "# Trazer dados para memória RAM \n",
    "nfe_entrada = NFeEntrada.retrieve()\n",
    "nfe_saida = NFeSaida.retrieve()\n",
    "nfce = NFCe.retrieve()\n",
    "\n",
    "eventos_nfe_entrada = DadosOperacoes.EventosNotas(tuple(nfe_entrada['CHAVE_ACESSO'].values)).retrieve()\n",
    "eventos_nfe_saida = DadosOperacoes.EventosNotas(tuple(nfe_saida['CHAVE_ACESSO'].values)).retrieve()\n",
    "eventos_nfce = DadosOperacoes.EventosNotasConsumidor(tuple(nfce['CHAVE_ACESSO'].values)).retrieve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_metodo = 'Auditoria de Operações e Prestações de Saída'\n",
    "texto = f\"No dia {dt.today().strftime('%d/%m/%Y')}, foi realizada auditoria de Operações e Prestações de Saída, por meio das seguintes verificações: \\n \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excluir_notas_canceladas(doc, eventos):\n",
    "    \"\"\" Eventos para exclusão de notas com eventos de cancelamento / desconhecimento \"\"\"\n",
    "    # Obter últimos eventos\n",
    "    ultimo_evento = eventos.groupby(['CHAVE_ACESSO'], as_index=False)[['SEQUENCIA_EVENTO']].max()\n",
    "    eventos_validos = eventos[['CHAVE_ACESSO', 'SEQUENCIA_EVENTO','CODIGO_EVENTO']].merge(ultimo_evento[['CHAVE_ACESSO', 'SEQUENCIA_EVENTO']], on = ['CHAVE_ACESSO', 'SEQUENCIA_EVENTO'], how='inner')\n",
    "\n",
    "    # Filtrar eventos de cancelamento\n",
    "    eventos_canc = eventos_validos[eventos_validos['CODIGO_EVENTO'].isin(['210220', '210240'])]\n",
    "\n",
    "    # Filtrar docs que não possuem eventos\n",
    "    doc_filtrado = doc.merge(eventos_canc, on = 'CHAVE_ACESSO', how='left', indicator=True)\n",
    "    doc_filtrado = doc_filtrado[doc_filtrado['_merge']=='left_only']\n",
    "    doc_filtrado.drop(columns=['_merge', 'SEQUENCIA_EVENTO', 'CODIGO_EVENTO'], inplace=True)\n",
    "\n",
    "    return doc_filtrado\n",
    "\n",
    "\n",
    "def inverter_cnpj_em_notas_entradas(doc):\n",
    "    # Inverter CNPJ_REM e CNPJ_DEST se TIPO_OPER = 'ENTRADA'\n",
    "    if 'TIPO_OPER' in doc.columns and 'CNPJ_ALTERADO' not in doc.columns:\n",
    "\n",
    "        # Invertendo CNPJ        \n",
    "        doc['CNPJ_REM_MOD'] = [linha['CNPJ_DEST'] if linha['TIPO_OPER']=='ENTRADA' else linha['CNPJ_REM'] for _, linha in doc.iterrows()]\n",
    "        doc['CNPJ_DEST_MOD'] = [linha['CNPJ_REM'] if linha['TIPO_OPER']=='ENTRADA' else linha['CNPJ_DEST'] for _, linha in doc.iterrows()]\n",
    "\n",
    "        doc.drop(columns=['CNPJ_DEST', 'CNPJ_REM'], inplace=True)\n",
    "        doc.rename(columns={'CNPJ_REM_MOD':'CNPJ_REM', 'CNPJ_DEST_MOD': 'CNPJ_DEST'}, inplace=True)\n",
    "        doc['CNPJ_ALTERADO'] = ['SIM' if linha['TIPO_OPER']=='ENTRADA' else 'NÃO' for _, linha in doc.iterrows()]\n",
    "\n",
    "    elif 'CNPJ_ALTERADO' in doc.columns:\n",
    "        print('Não invertido em virtude de já haver operação anterior de inversão.')\n",
    "\n",
    "    else:\n",
    "        print('Não invertido por outro erro qualquer.')\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfe_entrada = excluir_notas_canceladas(nfe_entrada, eventos_nfe_entrada)\n",
    "nfe_entrada = inverter_cnpj_em_notas_entradas(nfe_entrada)\n",
    "\n",
    "nfe_saida = excluir_notas_canceladas(nfe_saida, eventos_nfe_saida)\n",
    "nfe_saida = inverter_cnpj_em_notas_entradas(nfe_saida)\n",
    "\n",
    "# Adequar nfe_saida para ter apenas saídas e nfe_entrada para ter apenas entrada (migrar dados de cnpj invertidos entre as variáveis)\n",
    "nfe = pd.concat([nfe_entrada, nfe_saida])\n",
    "nfe_entrada = nfe[nfe['CNPJ_DEST']==cnpj]\n",
    "nfe_saida = nfe[nfe['CNPJ_REM']==cnpj]\n",
    "\n",
    "del nfe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Verificação de Desempenho Negativo (Por Mês)\n",
    "\n",
    "\n",
    "Art. 75. Os contribuintes do ICMS localizados neste Estado, que adquirirem mercadorias\n",
    "oriundas de outras unidades da Federação, ficam sujeitos ao recolhimento antecipado do imposto relativo à\n",
    "diferença entre a alíquota interna e a interestadual, pelas operações que venham realizar no território deste\n",
    "Estado.\n",
    "\n",
    "[...]\n",
    "\n",
    "Art. 76. Quando da passagem das mercadorias ou bens pela primeira repartição fiscal do Estado,\n",
    "a documentação fiscal correspondente será processada eletronicamente e emitido DARE para recolhimento\n",
    "do imposto, com vencimento no último dia da segunda quinzena subseqüente à da entrada neste Estado.\n",
    "\n",
    "[...]\n",
    "\n",
    "\n",
    "§ 3º. O prazo estabelecido no caput deste artigo não será aplicado aos contribuintes que se\n",
    "encontrem:\n",
    "\n",
    "\n",
    "III- com desempenho negativo.\n",
    "\n",
    "[...]\n",
    "\n",
    "\n",
    "§ 4º. Para efeito do disposto no inciso III do parágrafo anterior, considera-se desempenho\n",
    "negativo:\n",
    "\n",
    "I – a empresa apresentar no ano em curso, ou no anterior, volume de entradas superior ao de\n",
    "saídas;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_notas_mensal(doc, col_base='CNPJ_REM'):\n",
    "    \"\"\" Função para agrupar por mês, por coluna especificada (col_base)\"\"\"\n",
    "\n",
    "    new_doc = doc.groupby([col_base, pd.Grouper(key='DT_EMISSAO', freq='1M')], as_index=False)[['VALOR_BRUTO_ITEM',\n",
    "                                                                                            'VALOR_DESCONTO_ITEM', \n",
    "                                                                                            'VALOR_LIQUIDO_ITEM']].sum()\n",
    "    \n",
    "    new_doc.rename(columns={\n",
    "                            'VALOR_BRUTO_ITEM': 'VALOR_BRUTO',\n",
    "                            'VALOR_DESCONTO_ITEM': 'VALOR_DESCONTO', \n",
    "                            'VALOR_LIQUIDO_ITEM': 'VALOR_LIQUIDO'}, inplace=True\n",
    "                            )\n",
    "    \n",
    "    return new_doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatos = {}\n",
    "\n",
    "# Agrupar dados em base mensal\n",
    "nfe_entrada_agpt = agrupar_notas_mensal(nfe_entrada, col_base = 'CNPJ_DEST')\n",
    "nfe_saida_agpt = agrupar_notas_mensal(nfe_saida)\n",
    "nfce_agpt = agrupar_notas_mensal(nfce)\n",
    "\n",
    "# Calcular desempenho mensal\n",
    "saida_agpt = nfe_saida_agpt.merge(nfce_agpt, on = ['CNPJ_REM', 'DT_EMISSAO'], how='outer', suffixes=['', '_NFCE'], validate='one_to_one')\n",
    "total_agpt = saida_agpt.merge(nfe_entrada_agpt, left_on=['CNPJ_REM', 'DT_EMISSAO'], right_on=['CNPJ_DEST', 'DT_EMISSAO'], how='outer', suffixes=['_NFE_SAIDA', '_NFE_ENTRADA'], validate='one_to_one')\n",
    "\n",
    "# Alterar nomes de tabelas e manter apenas necessárias\n",
    "colunas = ['VALOR_BRUTO', 'VALOR_LIQUIDO']\n",
    "tipos = ['_NFCE', '_NFE_SAIDA', '_NFE_ENTRADA']\n",
    "\n",
    "colunas_a_manter = ['CNPJ_REM', 'DT_EMISSAO']\n",
    "colunas_a_manter = colunas_a_manter + [x+y for x in colunas for y in tipos]\n",
    "total_agpt = total_agpt[colunas_a_manter]\n",
    "\n",
    "total_agpt.rename(columns={'CNPJ_REM':'CNPJ'}, inplace=True)\n",
    "\n",
    "# Completando nulos com 0 \n",
    "total_agpt.fillna(0, inplace=True)\n",
    "\n",
    "# Calcular desempenho mensal\n",
    "\n",
    "\n",
    "for col in colunas:\n",
    "    total_agpt[col+'_RESULTADO'] = total_agpt[col+'_NFCE'] + total_agpt[col+'_NFE_SAIDA'] - total_agpt[col+'_NFE_ENTRADA'] \n",
    "\n",
    "total_agpt.sort_values(by='DT_EMISSAO', inplace=True)\n",
    "\n",
    "\n",
    "# Verificar se há desempenho negativo na maior parte do período e relatar\n",
    "if len(total_agpt[total_agpt['VALOR_LIQUIDO_RESULTADO']<0]) > (data_fim.year - data_inicio.year)/2 and total_agpt['VALOR_LIQUIDO_RESULTADO'].sum()< -valor_minimo_significancia: \n",
    "    msg = f\"\"\"\n",
    "O contribuinte possui {len(total_agpt[total_agpt['VALOR_LIQUIDO_RESULTADO']<0])} períodos com desempenho negativo mensal, somando o equivalente a R$ {total_agpt['VALOR_LIQUIDO_RESULTADO'].sum()} em desempenho no período de {data_inicio.strftime('%d/%m/%Y')} e {data_fim.strftime('%d/%m/%Y')}, conforme anexo {indice_anexo}.\n",
    "Em virtude disso, e considerando o Art. 75 e 76, §3º e §4º, I, do Decreto 4.335-E/2001, do RICMS-RR (Dec), considera-se que o contribuinte não poderá fazer jus a prazo para pagamento de Antecipação Parcial.\n",
    "\"\"\"\n",
    "    anexos[f'Anexo {indice_anexo} - Desempenho Mensalizado de Operações com Mercadorias'] = [total_agpt]\n",
    "    indice_anexo += 1 \n",
    "    del colunas, colunas_a_manter, tipos, saida_agpt, nfce_agpt, nfe_saida_agpt, nfe_entrada_agpt\n",
    "\n",
    "else:\n",
    "    msg = f'Não foi identificada irregularidade com o desempenho operacional do período.'\n",
    "    del total_agpt, colunas, colunas_a_manter, tipos, saida_agpt, nfce_agpt, nfe_saida_agpt, nfe_entrada_agpt\n",
    "\n",
    "criterio = 'Ausência de Desempenho Negativo (por mês)'\n",
    "\n",
    "\n",
    "\n",
    "explicacao_adicional = f\"\"\" Foi acessado o banco de dados da Receita Estadual (SEFAZ-RR) no dia {dt.today().strftime(\"%d/%m/%Y\")} com a finalidade de obtenção dos documentos fiscais em posse do Fisco. \n",
    "\\nBaseado nestes documentos, realizou-se as correções devidas (a fim de que as notas fiscais refletissem o Tipo de Nota Fiscal - Entrada ou Saída - e a Finalidade de Emissão - Normal ou Devolução), bem como a exclusão de documentos com eventos referentes a cancelamento (como, por exemplo, eventos de Não Realização da Operação ou de Desconhecimento). \n",
    "\\nUtilizou-se o somatório de documentos fiscais de saída (apenas NF-e e NFC-e) e o somatório de documentos fiscais de entrada, por mês e considerou-se a normal ocorrência de prejuízos em períodos alternados. \n",
    "\\nPara fins de classificação de uma situação como irregular, ponderou-se pela presença de desempenhos negativos em pelo menos {(data_fim.year - data_inicio.year)/2} ocorrências. \"\"\"\n",
    "\n",
    "# Documentar procedimento\n",
    "doc.inserir_procedimento(nome_metodo=nome_metodo, texto=texto, resultado=msg, texto_adicional=explicacao_adicional, criterio = criterio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Verificação de Desempenho Negativo por Produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Montar Livro de Entrada e Saída de Produtos baseado em GTIN\n",
    "entradas = nfe_entrada[['CNPJ_DEST', 'DT_EMISSAO', 'GTIN_ITEM', 'NCM_ITEM', 'DESCRICAO_PROD', 'QTDE_ITEM', 'UND_ITEM', 'VALOR_LIQUIDO_ITEM']]\n",
    "entradas.rename(columns={'CNPJ_DEST':'CNPJ'}, inplace=True)\n",
    "entradas['REGIME_COMPETENCIA'] = 'DESPENDIO'\n",
    "entradas['VALOR_LIQUIDO_ITEM'] = -1 * entradas['VALOR_LIQUIDO_ITEM'] \n",
    "\n",
    "saidas = pd.concat([nfe_saida[['CNPJ_REM', 'DT_EMISSAO', 'GTIN_ITEM', 'NCM_ITEM', 'DESCRICAO_PROD', 'QTDE_ITEM', 'UND_ITEM', 'VALOR_LIQUIDO_ITEM']], nfce[['CNPJ_REM', 'DT_EMISSAO', 'GTIN_ITEM', 'NCM_ITEM', 'DESCRICAO_PROD', 'QTDE_ITEM', 'UND_ITEM', 'VALOR_LIQUIDO_ITEM']]])\n",
    "saidas.rename(columns={'CNPJ_REM':'CNPJ'}, inplace=True)\n",
    "saidas['REGIME_COMPETENCIA'] = 'RECEITA'\n",
    "\n",
    "estoque = pd.concat([entradas, saidas])\n",
    "estoque.sort_values(by='DT_EMISSAO', inplace=True)\n",
    "\n",
    "# Considerar SAÍDAS como valor POSITIVO e ENTRADAS como valor NEGATIVO (SAÍDA = RECEITA e ENTRADA = DESPÊNDIO)\n",
    "\n",
    "# Separar por estoque industrializado \n",
    "estoque_industrializado = estoque[~estoque['GTIN_ITEM'].isin(['SEM GTIN', 'None'])]\n",
    "estoque_primario = estoque[estoque['GTIN_ITEM'].isin(['SEM GTIN', 'None'])]\n",
    "del estoque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estoque_industrializado['DESEMPENHO_DIARIO_PRODUTO'] = estoque_industrializado.groupby('GTIN_ITEM')['VALOR_LIQUIDO_ITEM'].cumsum()\n",
    "# estoque_industrializado.sort_values(by=['GTIN_ITEM', 'DT_EMISSAO'], inplace=True)\n",
    "# # estoque_industrializado.set_index(['CNPJ', 'GTIN_ITEM', 'DT_EMISSAO'], inplace=True)\n",
    "# estoque_industrializado.to_excel('aaa.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import re\n",
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# # Assuming 'df' is your DataFrame\n",
    "\n",
    "# # Step 1: Data Preprocessing\n",
    "# def preprocess_text(text):\n",
    "#     # Convert to lowercase\n",
    "#     text = str(text).lower()\n",
    "#     # Remove special characters and numbers\n",
    "#     text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "#     # Remove extra spaces\n",
    "#     text = re.sub(r'\\s+', ' ', text).strip()\n",
    "#     return text\n",
    "\n",
    "# def ProcessarDescricoesProdutos(df):\n",
    "#     df['DESCRICAO_PROD_PROCESSADO'] = df['DESCRICAO_PROD'].apply(preprocess_text)\n",
    "\n",
    "#     # Step 2: Generate Text Embeddings\n",
    "#     model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#     embeddings = model.encode(df['DESCRICAO_PROD_PROCESSADO'].tolist())\n",
    "\n",
    "#     # Step 3: Clustering Similar Product Descriptions\n",
    "#     # Adjust the distance_threshold based on your data\n",
    "#     clustering_model = AgglomerativeClustering(\n",
    "#         n_clusters=None,\n",
    "#         distance_threshold=0.5,\n",
    "#         metric='cosine',\n",
    "#         linkage='average'\n",
    "#     )\n",
    "#     clustering_model.fit(embeddings)\n",
    "#     df['Description_Cluster'] = clustering_model.labels_\n",
    "\n",
    "\n",
    "#     df['ID_PRODUTO_POR_DESCRICAO'] = ['Cluster' + str(line['Description_Cluster']) for _, line in df.iterrows()]\n",
    "           \n",
    "\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estoque_industrializado2 = ProcessarDescricoesProdutos(estoque_industrializado)\n",
    "\n",
    "# estoque_industrializado2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Auditoria de Faturamento\n",
    "\n",
    "Objetivos:\n",
    "- Avaliar se o faturamento declarado é compatível com o somatório de notas fiscais emitidas \n",
    "- Avaliar se o faturamento declarado é compatível com a entrada de mercadoria para revenda no período\n",
    "- Avaliar se o faturamento declarado é compatível com o valor de notas fiscais para uso próprio (uso e consumo e ativo imobilizado)\n",
    "\n",
    "---\n",
    "<center> Fundamentos Legais </center>\n",
    "\n",
    "---\n",
    "\n",
    "> Resolução CGSN 140/2018\n",
    "\n",
    "Art. 81. A exclusão do Simples Nacional, mediante comunicação da ME ou da EPP à RFB, em aplicativo disponibilizado no Portal do Simples Nacional, dar-se-á:\n",
    "\n",
    "[...]\n",
    "\n",
    "II - obrigatoriamente, quando:\n",
    "\n",
    "a) a receita bruta acumulada ultrapassar um dos limites previstos no § 1º do art. 2º, hipótese em que a exclusão deverá ser comunicada:\n",
    "\n",
    "1. até o último dia útil do mês subsequente à ultrapassagem em mais de 20% (vinte por cento) de um desses limites, produzindo efeitos a partir do mês subsequente ao do excesso; ou (Lei Complementar nº 123, de 2006, art. 30, inciso IV, § 1º, inciso IV; art. 31, inciso V, alínea “a”)\n",
    "2. até o último dia útil do mês de janeiro do ano-calendário subsequente, na hipótese de não ter ultrapassado em mais de 20% (vinte por cento) um desses limites, produzindo efeitos a partir do ano-calendário subsequente ao do excesso; (Lei Complementar nº 123, de 2006, art. 30, inciso IV, § 1º, inciso IV; art. 31, inciso V, alínea “b”)\n",
    "\n",
    "b) a receita bruta acumulada, no ano-calendário de início de atividade, ultrapassar um dos limites previstos no caput do art. 3º, hipótese em que a exclusão deverá ser comunicada:\n",
    "\n",
    "1. até o último dia útil do mês subsequente à ultrapassagem em mais de 20% (vinte por cento) de um desses limites, produzindo efeitos retroativamente ao início de atividades; ou (Lei Complementar nº 123, de 2006, art. 30, inciso III, § 1º, inciso III, alínea “a”; art. 31, inciso III, alínea “a”)\n",
    "2. até o último dia útil do mês de janeiro do ano-calendário subsequente, na hipótese de não ter ultrapassado em mais de 20% (vinte por cento) um desses limites, produzindo efeitos a partir de 1º de janeiro do ano-calendário subsequente; (Lei Complementar nº 123, de 2006, art. 30, inciso III, § 1º, inciso III, alínea “b”; art. 31, inciso III, alínea “b”)\n",
    "\n",
    "[...]\n",
    "\n",
    "IV - a partir do próprio mês em que incorridas, hipótese em que a empresa ficará impedida de fazer nova opção pelo Simples Nacional nos 3 (três) anos-calendário subsequentes, nas seguintes hipóteses: (Lei Complementar nº 123, de 2006, art. 29, incisos II a XII e § 1º)\n",
    "\n",
    "[...]\n",
    "\n",
    "h) se for constatado que durante o ano-calendário o valor das despesas pagas supera em 20% (vinte por cento) o valor de ingressos de recursos no mesmo período, excluído o ano de início de atividade;\n",
    "\n",
    "i) se for constatado que durante o ano-calendário o valor das aquisições de mercadorias para comercialização ou industrialização, ressalvadas hipóteses justificadas de aumento de estoque, foi superior a 80% (oitenta por cento) dos ingressos de recursos no mesmo período, excluído o ano de início de atividade;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_metodo = 'Auditoria de Faturamento'\n",
    "texto = f\"No dia {dt.today().strftime('%d/%m/%Y')}, foi realizada auditoria de Faturamento, por meio das seguintes verificações: \\n \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Verificação de Faturamento em relação às Notas Fiscais de saída"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1. Calcular Faturamento via Documentos Fiscais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNPJ</th>\n",
       "      <th>MES_REF</th>\n",
       "      <th>VALOR_FATURAMENTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29563548000121</td>\n",
       "      <td>01/2022</td>\n",
       "      <td>64480.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CNPJ  MES_REF  VALOR_FATURAMENTO\n",
       "0  29563548000121  01/2022           64480.83"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relatos = {}\n",
    "\n",
    "# Obter dado total de nfe de saída\n",
    "nfe_saida_total = nfe_saida[['CHAVE_ACESSO', 'CNPJ_REM', 'DT_EMISSAO', 'VALOR_FINAL_NOTA', 'TIPO_OPER', 'FINALIDADE']].drop_duplicates()\n",
    "\n",
    "# Excluir devoluções (não compõem faturamento)\n",
    "nfe_saida_total = nfe_saida_total[nfe_saida_total['FINALIDADE']=='NORMAL']\n",
    "\n",
    "# Reduzir colunas para somar com nfces\n",
    "nfe_saida_total = nfe_saida_total[['CHAVE_ACESSO', 'CNPJ_REM', 'DT_EMISSAO', 'VALOR_FINAL_NOTA']]\n",
    "\n",
    "# Inserir modelo \n",
    "nfe_saida_total['MODELO'] = 'NF-e'\n",
    "nfce['MODELO'] = 'NFC-e'\n",
    "\n",
    "# Gerar dataframe com saídas\n",
    "saidas_total = pd.concat([nfe_saida_total, nfce[['CHAVE_ACESSO', 'CNPJ_REM', 'DT_EMISSAO', 'VALOR_FINAL_NOTA', 'MODELO']].drop_duplicates()])\n",
    "saidas_total.rename(columns={'CNPJ_REM':'CNPJ'}, inplace=True)\n",
    "\n",
    "# Calcular valor total de faturamento (por meio de documentação de saída)\n",
    "faturamento_nf = saidas_total.groupby(['CNPJ', pd.Grouper(key='DT_EMISSAO', freq='1M')], as_index=False)[['VALOR_FINAL_NOTA']].sum()\n",
    "faturamento_nf['DT_EMISSAO'] = faturamento_nf['DT_EMISSAO'].dt.strftime('%m/%Y')\n",
    "\n",
    "# Alterar nomes\n",
    "faturamento_nf.columns = ['CNPJ', 'MES_REF', 'VALOR_FATURAMENTO']\n",
    "\n",
    "faturamento_nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2. Identificar faturamento declarado em PGDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  could not open file \"global/pg_filenode.map\": No such device\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3288\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3267\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3268\u001b[0m \n\u001b[0;32m   3269\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3286\u001b[0m \n\u001b[0;32m   3287\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:452\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:1267\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1267\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:716\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:169\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:167\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:393\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:678\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 678\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:902\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 902\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    903\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:898\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\create.py:637\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\default.py:615\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m _connect(dsn, connection_factory\u001b[38;5;241m=\u001b[39mconnection_factory, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOperationalError\u001b[0m: connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  could not open file \"global/pg_filenode.map\": No such device\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pgdas_declarados \u001b[38;5;241m=\u001b[39m \u001b[43mpgdas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m pgdas_declarados[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDT_INI\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(pgdas_declarados[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDT_INI\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m faturamento_pgdas \u001b[38;5;241m=\u001b[39m pgdas_declarados\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNPJ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDT_INI\u001b[39m\u001b[38;5;124m'\u001b[39m], as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVltotal\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\Documents\\Auditor_Fiscal\\Planos de Trabalho - DIFIS\\022024\\Automatização\\connection.py:417\u001b[0m, in \u001b[0;36mDadosEscriturais.PGDAS.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m connection:\n\u001b[0;32m    418\u001b[0m         pgdas \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery, con\u001b[38;5;241m=\u001b[39mconnection)\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecuperado \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pgdas)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m registros!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3264\u001b[0m, in \u001b[0;36mEngine.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[0;32m   3242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[0;32m   3243\u001b[0m \n\u001b[0;32m   3244\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3261\u001b[0m \n\u001b[0;32m   3262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:147\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 147\u001b[0m         \u001b[43mConnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2426\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[1;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[0;32m   2424\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2425\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2427\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2428\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    147\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[0;32m    148\u001b[0m             err, dialect, engine\n\u001b[0;32m    149\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3288\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m   3267\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3268\u001b[0m \n\u001b[0;32m   3269\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3286\u001b[0m \n\u001b[0;32m   3287\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:452\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m    445\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:1267\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_checkout\u001b[39m(\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1264\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[0;32m   1266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1267\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1270\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:716\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    714\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:169\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:167\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:393\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[0;32m    391\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:678\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 678\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:902\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 902\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    903\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\pool\\base.py:898\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\create.py:637\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    635\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\default.py:615\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32mc:\\Users\\Jimmy_Usuário\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m _connect(dsn, connection_factory\u001b[38;5;241m=\u001b[39mconnection_factory, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: (psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  could not open file \"global/pg_filenode.map\": No such device\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "pgdas_declarados = pgdas.retrieve()\n",
    "\n",
    "pgdas_declarados['DT_INI'] = pd.to_datetime(pgdas_declarados['DT_INI'])\n",
    "faturamento_pgdas = pgdas_declarados.groupby(['CNPJ', 'DT_INI'], as_index=False)[['Vltotal']].sum()\n",
    "faturamento_pgdas['MES_REF'] = faturamento_pgdas['DT_INI'].dt.strftime('%m/%Y')\n",
    "faturamento_pgdas = faturamento_pgdas[['CNPJ', 'MES_REF', 'Vltotal']]\n",
    "# Alterar nomes de coluna\n",
    "faturamento_pgdas.columns = ['CNPJ', 'MES_REF', 'VALOR_FATURAMENTO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.3. Cruzar faturamento calculado com faturamento declarado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruzamento_faturamento = faturamento_nf.merge(faturamento_pgdas, on=['CNPJ', 'MES_REF'], how='outer', validate='one_to_one', suffixes=['_NF', '_PGDAS'])\n",
    "\n",
    "cruzamento_faturamento['DIFERENCA_FATURAMENTO'] = cruzamento_faturamento['VALOR_FATURAMENTO_NF'] - cruzamento_faturamento['VALOR_FATURAMENTO_PGDAS']\n",
    "\n",
    "# Calcular possível valor de irregularidade \n",
    "diferenca_fat = round(abs(cruzamento_faturamento[cruzamento_faturamento['DIFERENCA_FATURAMENTO'] >= 0]['DIFERENCA_FATURAMENTO'].sum()), 2)\n",
    "\n",
    "\n",
    "if (cruzamento_faturamento[cruzamento_faturamento['DIFERENCA_FATURAMENTO'] >= 0].size >= (data_fim.year - data_inicio.year)/2) \\\n",
    "    and diferenca_fat >= valor_minimo_significancia:\n",
    "    msg = f\"Foi identificada irregularidade significativa na comparação entre faturamento declarado e faturamento calculado no montante total de R$ {diferenca_fat} no período fiscalizado, conforme Anexo {indice_anexo}.\"\n",
    "    \n",
    "\n",
    "else:\n",
    "    msg = f\"Não foi identificada irregularidade significativa na comparação entre faturamento declarado e faturamento calculado no período fiscalizado, conforme Anexo {indice_anexo}.\"\n",
    "\n",
    "anexos[f\"Anexo {indice_anexo} - Diferença entre faturamentos mensais calculados e declarados\"] = [cruzamento_faturamento]\n",
    "indice_anexo += 1 \n",
    "criterio = 'Faturamento declarado em PGDAS compatível com as emissões de documentos fiscais de saída'\n",
    "del faturamento_nf, faturamento_pgdas\n",
    "\n",
    "explicacao_adicional = f\"\"\"Para a verificação de Faturamento declarado em PGDAS em relação às Notas Fiscais de saída, foi acessado o banco de dados da Receita Estadual (SEFAZ-RR) no dia {dt.today().strftime(\"%d/%m/%Y\")} com a finalidade de obtenção dos documentos fiscais em posse do Fisco. Para os documentos declaratórios de faturamento mensal, utilizou-se o Portal do Simples Nacional.\n",
    "\\nBaseado nestes documentos, realizou-se as correções devidas (a fim de que as notas fiscais refletissem o Tipo de Nota Fiscal - Entrada ou Saída - e a Finalidade de Emissão - Normal ou Devolução), bem como a exclusão de documentos com eventos referentes a cancelamento (como, por exemplo, eventos de Não Realização da Operação ou de Desconhecimento). \n",
    "\\nUtilizou-se o somatório de documentos fiscais de saída (apenas NF-e e NFC-e), por mês e considerou-se a normal ocorrência de inconsistências entre um mês e outro. \n",
    "\\nPara fins de classificação de uma situação como irregular, no que tange ao faturamento declarado e calculado, ponderou-se pela presença de inconsistências em pelo menos {(data_fim.year - data_inicio.year)/2} ocorrências, com somatório atual de irregularidades acima do valor de significância (R$ {valor_minimo_significancia}).\"\"\"\n",
    "\n",
    "# Documentar procedimento\n",
    "doc.inserir_procedimento(nome_metodo=nome_metodo, texto=texto, resultado=msg, texto_adicional=explicacao_adicional, criterio = criterio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Verificação de Excesso de Aquisições de Mercadorias em Relação ao Faturamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular total de entrada de mercadoria\n",
    "nfe_entrada_total = nfe_entrada[['CHAVE_ACESSO', 'CNPJ_DEST', 'DT_EMISSAO', 'FINALIDADE', 'CFOP_ITEM', 'VALOR_LIQUIDO_ITEM']]\n",
    "\n",
    "# Trocar nomes para tornar mais claro\n",
    "nfe_entrada_total.columns = ['CHAVE_ACESSO', 'CNPJ', 'DT_EMISSAO', 'FINALIDADE', 'CFOP_ITEM', 'VALOR_LIQUIDO_ITEM']\n",
    "\n",
    "# Excluir devoluções (entradas em virtude de devoluções não deveriam compor o conceito de \"aquisições de mercadoria\")\n",
    "nfe_entrada_total = nfe_entrada_total[nfe_entrada_total['FINALIDADE']!='DEVOLUÇÃO']\n",
    "\n",
    "# Excluir CFOP referente a uso e consumo\n",
    "CFOP_USO_CONSUMO = [principal+acessorio for principal in ['1', '2', '3', '5', '6', '7'] for acessorio in ['407', '550', '551', '552', '553', '554', '555', '556', '557']]\n",
    "nfe_entrada_total = nfe_entrada_total[~nfe_entrada_total['CFOP_ITEM'].isin(CFOP_USO_CONSUMO)]\n",
    "\n",
    "# Obter valor total de aquisições por ano-exercício\n",
    "nfe_entrada_total = nfe_entrada_total.groupby(['CNPJ', pd.Grouper(key='DT_EMISSAO', freq='1Y')], as_index=False)[['VALOR_LIQUIDO_ITEM']].sum()\n",
    "nfe_entrada_total.columns = ['CNPJ', 'ANO_REF', 'VALOR_AQUISIÇÕES']\n",
    "\n",
    "# Alterar formato de data para ANO\n",
    "nfe_entrada_total['ANO_REF'] = nfe_entrada_total['ANO_REF'].dt.strftime('%Y')\n",
    "\n",
    "# Obter Faturamento declarado\n",
    "pgdas_declarados = pgdas.retrieve()\n",
    "\n",
    "faturamento_pgdas = pgdas_declarados.groupby(['CNPJ', 'DT_INI'], as_index=False)[['Vltotal']].sum()\n",
    "faturamento_pgdas['DT_INI'] = pd.to_datetime(faturamento_pgdas['DT_INI'])\n",
    "# Alterar nomes de coluna\n",
    "faturamento_pgdas.columns = ['CNPJ', 'ANO_REF', 'VALOR_FATURAMENTO']\n",
    "\n",
    "# Alterar formato de data para ANO\n",
    "faturamento_pgdas['ANO_REF'] = faturamento_pgdas['ANO_REF'].dt.strftime('%Y')\n",
    "faturamento_pgdas = faturamento_pgdas.groupby(['CNPJ', 'ANO_REF'], as_index=False)[['VALOR_FATURAMENTO']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruzar faturamento com aquisições\n",
    "cruzamento_aquisicoes = faturamento_pgdas.merge(nfe_entrada_total, on = ['CNPJ', 'ANO_REF'], how='outer', validate='one_to_one')\n",
    "\n",
    "cruzamento_aquisicoes['PROPORCAO_AQUISICAO'] = cruzamento_aquisicoes['VALOR_AQUISIÇÕES'] / cruzamento_aquisicoes['VALOR_FATURAMENTO']\n",
    "\n",
    "# Verificar eventual irregularidade \n",
    "if cruzamento_aquisicoes[cruzamento_aquisicoes['PROPORCAO_AQUISICAO']>= 0.8].size > 0:\n",
    "    msg = \"\"\"Foi identificado que o contribuinte adquiriu valores superiores a 80% ao faturamento do período no(s) período(s) de: \n",
    "        \"\"\"\n",
    "    for idx, row in cruzamento_aquisicoes[cruzamento_aquisicoes['PROPORCAO_AQUISICAO']>= 0.8].iterrows():\n",
    "        msg += '- '\n",
    "        msg += row['ANO_REF'] \n",
    "        msg += f\": - R$ {round(row['VALOR_AQUISIÇÕES'], 2)} de aquisições e R$ {round(row['VALOR_FATURAMENTO'], 2)} de faturamento declarado - Proporção de {round(row['PROPORCAO_AQUISICAO'], 2)}\"  \n",
    "        msg += \"\"\"\n",
    "        \"\"\"\n",
    "    msg += f\"Conforme anexo {indice_anexo}\"\n",
    "    \n",
    "else:\n",
    "    msg = \"Não foi identificado irregularidades na proporção entre as aquisições de mercadoria no período e o faturamento declarado.\"\n",
    "\n",
    "anexos[f\"Anexo {indice_anexo} - Proporção de Aquisições em Relação ao Faturamento\"] = [cruzamento_aquisicoes]\n",
    "indice_anexo += 1 \n",
    "criterio = 'Faturamento declarado em PGDAS compatível com o recebimento de notas fiscais de entrada com mercadorias'\n",
    "\n",
    "\n",
    "explicacao_adicional = f\"\"\"\n",
    "Para a verificação de Excesso de Aquisições de Mercadorias por Notas Fiscais Eletrônicas em Relação ao Faturamento declarado em PGDAS, foi acessado o banco de dados da Receita Estadual (SEFAZ-RR) no dia {dt.today().strftime(\"%d/%m/%Y\")} com a finalidade de obtenção dos documentos fiscais em posse do Fisco. Já para os documentos declaratórios de faturamento mensal, utilizou-se o Portal do Simples Nacional.\n",
    "\\nBaseado nestes documentos, realizou-se as correções devidas (a fim de que as notas fiscais refletissem o Tipo de Nota Fiscal - Entrada ou Saída - e a Finalidade de Emissão - Normal ou Devolução), bem como a exclusão de documentos com eventos referentes a cancelamento (como, por exemplo, eventos de Não Realização da Operação ou de Desconhecimento). \n",
    "\\nUtilizou-se o somatório de documentos fiscais de aquisições (apenas NF-e) no período (por ano), desde que NÃO possuíssem CFOP de uso e consumo (ou uso como ativo imobilizado). \n",
    "\\nPara fins de classificação de uma situação como irregular, para as aquisições de mercadorias em relação ao faturamento, ponderou-se pela presença de inconsistências em pelo menos 1 período de 12 meses, coincidente com o ano-calendário. \"\"\"\n",
    "print(msg)\n",
    "# Documentar procedimento\n",
    "doc.inserir_procedimento(nome_metodo=nome_metodo, texto=texto, resultado=msg, texto_adicional=explicacao_adicional, criterio = criterio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Verificação de Excesso de Despesas em Relação ao Faturamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular total de entrada de mercadoria\n",
    "nfe_entrada_total = nfe_entrada[['CHAVE_ACESSO', 'CNPJ_DEST', 'DT_EMISSAO', 'FINALIDADE', 'CFOP_ITEM', 'VALOR_LIQUIDO_ITEM']]\n",
    "\n",
    "# Trocar nomes para tornar mais claro\n",
    "nfe_entrada_total.columns = ['CHAVE_ACESSO', 'CNPJ', 'DT_EMISSAO', 'FINALIDADE', 'CFOP_ITEM', 'VALOR_LIQUIDO_ITEM']\n",
    "\n",
    "# Excluir devoluções (entradas em virtude de devoluções não deveriam compor o conceito de \"aquisições de mercadoria\")\n",
    "nfe_entrada_total = nfe_entrada_total[nfe_entrada_total['FINALIDADE']!='DEVOLUÇÃO']\n",
    "\n",
    "# Filtrar por CFOP referente a uso e consumo\n",
    "CFOP_USO_CONSUMO = [principal+acessorio for principal in ['1', '2', '3', '5', '6', '7'] for acessorio in ['407', '550', '551', '552', '553', '554', '555', '556', '557']]\n",
    "nfe_entrada_total = nfe_entrada_total[nfe_entrada_total['CFOP_ITEM'].isin(CFOP_USO_CONSUMO)]\n",
    "\n",
    "# Obter valor total de aquisições por ano-exercício\n",
    "nfe_entrada_total = nfe_entrada_total.groupby(['CNPJ', pd.Grouper(key='DT_EMISSAO', freq='1Y')], as_index=False)[['VALOR_LIQUIDO_ITEM']].sum()\n",
    "nfe_entrada_total.columns = ['CNPJ', 'ANO_REF', 'VALOR_DESPESAS_USO_CONSUMO']\n",
    "\n",
    "# Alterar formato de data para ANO\n",
    "nfe_entrada_total['ANO_REF'] = nfe_entrada_total['ANO_REF'].dt.strftime('%Y')\n",
    "\n",
    "# Obter Faturamento declarado\n",
    "pgdas_declarados = pgdas.retrieve()\n",
    "\n",
    "faturamento_pgdas = pgdas_declarados.groupby(['CNPJ', 'DT_INI'], as_index=False)[['Vltotal']].sum()\n",
    "faturamento_pgdas['DT_INI'] = pd.to_datetime(faturamento_pgdas['DT_INI'])\n",
    "# Alterar nomes de coluna\n",
    "faturamento_pgdas.columns = ['CNPJ', 'ANO_REF', 'VALOR_FATURAMENTO']\n",
    "\n",
    "# Alterar formato de data para ANO\n",
    "faturamento_pgdas['ANO_REF'] = faturamento_pgdas['ANO_REF'].dt.strftime('%Y')\n",
    "faturamento_pgdas = faturamento_pgdas.groupby(['CNPJ', 'ANO_REF'], as_index=False)[['VALOR_FATURAMENTO']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruzar faturamento com aquisições\n",
    "cruzamento_despesas = faturamento_pgdas.merge(nfe_entrada_total, on = ['CNPJ', 'ANO_REF'], how='outer', validate='one_to_one')\n",
    "\n",
    "cruzamento_despesas['PROPORCAO_DESPESAS'] = cruzamento_despesas['VALOR_DESPESAS_USO_CONSUMO'] / cruzamento_despesas['VALOR_FATURAMENTO']\n",
    "\n",
    "# Verificar eventual irregularidade \n",
    "if cruzamento_despesas[cruzamento_despesas['PROPORCAO_DESPESAS']>= 0.2].size > 0:\n",
    "    msg = \"\"\"Foi identificado que o contribuinte realizou despesas com Uso e Consumo em valores superiores a 20% ao faturamento do período no(s) período(s) de: \n",
    "        \"\"\"\n",
    "    for idx, row in cruzamento_despesas[cruzamento_despesas['PROPORCAO_DESPESAS']>= 0.2].iterrows():\n",
    "        msg += '- '\n",
    "        msg += row['ANO_REF'] \n",
    "        msg += f\": - R$ {round(row['VALOR_DESPESAS_USO_CONSUMO'], 2)} de despesas e R$ {round(row['VALOR_FATURAMENTO'], 2)} de faturamento declarado - Proporção de {round(row['PROPORCAO_DESPESAS'], 2)}\"  \n",
    "        msg += \"\"\"\n",
    "        \"\"\"\n",
    "    msg += f\"Conforme anexo {indice_anexo}\"\n",
    "    \n",
    "else:\n",
    "    msg = \"Não foi identificado irregularidades na proporção entre as despesas por produtos de uso e consumo no período e o faturamento declarado.\"\n",
    "\n",
    "anexos[f\"Anexo {indice_anexo} - Proporção de Despesas em Relação ao Faturamento\"] = [cruzamento_despesas]\n",
    "indice_anexo += 1 \n",
    "criterio = 'Faturamento declarado em PGDAS compatível com as despesas declaradas em Notas Fiscais'\n",
    "\n",
    "explicacao_adicional = f\"\"\"Para a verificação de Excesso de Despesas por meio de Notas Fiscais em Relação ao Faturamento declarado em PGDAS, foi acessado o banco de dados da Receita Estadual (SEFAZ-RR) no dia {dt.today().strftime(\"%d/%m/%Y\")} com a finalidade de obtenção dos documentos fiscais em posse do Fisco. Para os documentos declaratórios de faturamento mensal, utilizou-se o Portal do Simples Nacional.\n",
    "\\nBaseado nestes documentos, realizou-se as correções devidas (a fim de que as notas fiscais refletissem o Tipo de Nota Fiscal - Entrada ou Saída - e a Finalidade de Emissão - Normal ou Devolução), bem como a exclusão de documentos com eventos referentes a cancelamento (como, por exemplo, eventos de Não Realização da Operação ou de Desconhecimento). \n",
    "\\nUtilizou-se o somatório de documentos fiscais de aquisições (apenas NF-e) no período (por ano), desde que possuíssem CFOP de uso e consumo (ou ativo imobilizado). \n",
    "\\nPara fins de classificação de uma situação como irregular, para as aquisições de mercadorias em relação ao faturamento, ponderou-se pela presença de inconsistências em pelo menos 1 período de 12 meses, coincidente com o ano-calendário. \"\"\"\n",
    "\n",
    "print(msg)\n",
    "# Documentar procedimento\n",
    "doc.inserir_procedimento(nome_metodo=nome_metodo, texto=texto, resultado=msg, texto_adicional=explicacao_adicional, criterio = criterio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusão de Relatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concluir relatório\n",
    "doc.concluir_auditoria()\n",
    "\n",
    "# Salvar\n",
    "doc.salvar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
